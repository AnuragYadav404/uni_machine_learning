{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the Efficacy of Two-Class Cost Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import autograd wrapped numpy\n",
    "import autograd.numpy as np\n",
    "\n",
    "# imports from custom library\n",
    "from mlrefined_libraries import basics_library as baslib\n",
    "from mlrefined_libraries import calculus_library as calib\n",
    "from mlrefined_libraries import math_optimization_library as optlib\n",
    "from mlrefined_libraries import superlearn_library as superlearn\n",
    "\n",
    "# demos for this notebook\n",
    "regress_plotter = superlearn.lin_regression_demos\n",
    "optimizers = optlib.optimizers\n",
    "static_plotter = optlib.static_plotter.Visualizer();\n",
    "plotter = superlearn.multi_outupt_plotters\n",
    "\n",
    "# load in baic libraries\n",
    "from autograd import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "datapath = '../mlrefined_datasets/superlearn_datasets/'\n",
    "\n",
    "# this is needed to compensate for matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we load in the breast cancer dataset -  [a description of which you can find here](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)).  The input datapoints are stacked *column-wise* in this dataset, with the final row being the label of each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data input\n",
    "csvname = datapath + 'breast_cancer_data.csv'\n",
    "data1 = np.loadtxt(csvname,delimiter = ',')\n",
    "\n",
    "# get input and output of dataset\n",
    "x = data1[:-1,:]\n",
    "y = data1[-1:,:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `x` contains an input point in each column - there are $N=8$ input features and $P=699$ datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `y` contains the labels for each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we implement each of the required cost functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute linear combination of input points\n",
    "def model(x,w):\n",
    "    # to-do\n",
    "    a = ......\n",
    "    return a.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Implement the perceptron cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an implementation of the perceptron cost\n",
    "def perceptron(w):    \n",
    "    # compute the perceptron cost\n",
    "    # to-do\n",
    "    cost = .....\n",
    "    return cost/float(np.size(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Implement the softmax cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an implementation of the softmax cost\n",
    "def softmax(w):    \n",
    "    # compute the softmax cost\n",
    "    # to-do\n",
    "    cost = .....\n",
    "    return cost/float(np.size(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup data\n",
    "N = x.shape[0]\n",
    " \n",
    "# setup optimizer input\n",
    "alpha = 10**(-1)\n",
    "max_its = 1000\n",
    "\n",
    "w = np.array([[ 0.00053047], \n",
    "              [ 0.10586749], \n",
    "              [ 0.03009413], \n",
    "              [-0.02545688], \n",
    "              [-0.11771576], \n",
    "              [-0.0214547 ], \n",
    "              [-0.09508718], \n",
    "              [ 0.07190713], \n",
    "              [-0.19779308]])\n",
    "\n",
    "# run gradient descent to minimize the Least Squares cost for linear regression\n",
    "g = perceptron;\n",
    "weight_history_1,cost_history_1 = optimizers.gradient_descent(g,alpha,max_its,w)\n",
    "\n",
    "alpha = 10**(0)\n",
    "g = softmax;\n",
    "weight_history_2,cost_history_2 = optimizers.gradient_descent(g,alpha,max_its,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Construct misclassification counter\n",
    "Count the number of missclassifications for a given w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counting_cost(w,x,y):\n",
    "    # compute predicted labels\n",
    "    #to do\n",
    "    y_hat = .....\n",
    "\n",
    "    # compare to true labels\n",
    "    #to do\n",
    "     cost = ........\n",
    "    # return number of misclassifications\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create misclassification history for each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_history_1 = [counting_cost(v,x,y) for v in weight_history_1]\n",
    "count_history_2 = [counting_cost(v,x,y) for v in weight_history_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Plot cost and count histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "classif_plotter = superlearn.classification_static_plotter.Visualizer()\n",
    "\n",
    "cost_histories = [cost_history_1,cost_history_2]\n",
    "count_histories = [count_history_1,count_history_2]\n",
    "\n",
    "#to do\n",
    "classif_plotter.plot_cost_histories(.....)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "364.767px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "315.867px",
    "left": "1px",
    "right": "1227px",
    "top": "116.267px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
